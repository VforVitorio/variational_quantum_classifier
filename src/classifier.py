"""
Clasificador Cu√°ntico Variacional (VQC)

Este m√≥dulo implementa la clase principal del clasificador cu√°ntico, combinando
el circuito cu√°ntico parametrizado con optimizaci√≥n cl√°sica para aprendizaje
autom√°tico h√≠brido.

Componentes:
    - QuantumClassifier: Clase principal que encapsula el modelo VQC
    - Funci√≥n de costo: Calcula error de clasificaci√≥n
    - Optimizaci√≥n: Integraci√≥n con scipy.optimize (COBYLA, Nelder-Mead)
    - Evaluaci√≥n: M√©tricas de accuracy y persistencia de par√°metros

Algoritmo de entrenamiento:
    1. Inicializar par√°metros aleatoriamente
    2. Para cada iteraci√≥n:
        a. Predecir clases con par√°metros actuales
        b. Calcular error (funci√≥n de costo)
        c. Optimizador ajusta par√°metros
    3. Converger cuando error deja de disminuir

Funciones:
    QuantumClassifier: Clase del clasificador completo
"""

import numpy as np
from scipy.optimize import minimize
from typing import Tuple, Optional, Dict
import time
import pickle
import sys
import os

# A√±adir directorio padre al path para imports
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

try:
    from src.quantum_circuit import predict_single_point, predict_batch
except ModuleNotFoundError:
    from quantum_circuit import predict_single_point, predict_batch


# =============================================================================
# QUANTUM CLASSIFIER CLASS
# =============================================================================

class QuantumClassifier:
    """
    Clasificador Cu√°ntico Variacional para clasificaci√≥n binaria.

    Implementa un modelo h√≠brido cu√°ntico-cl√°sico que:
    - Codifica datos en estados cu√°nticos
    - Aplica transformaciones parametrizadas
    - Optimiza par√°metros mediante algoritmos cl√°sicos

    Attributes:
        n_qubits: N√∫mero de qubits en el circuito
        n_params: N√∫mero de par√°metros entrenables
        shots: Repeticiones por medici√≥n
        params: Par√°metros actuales del modelo
        training_history: Historial de entrenamiento
    """

    def __init__(self, n_qubits: int = 2, n_params: int = 4, shots: int = 100, n_layers: int = 1):
        """
        Inicializa el clasificador cu√°ntico.

        Args:
            n_qubits: N√∫mero de qubits (default: 2)
            n_params: N√∫mero de par√°metros (default: 4 para 1 capa, 8 para 2 capas)
            shots: Shots por medici√≥n (default: 100)
            n_layers: N√∫mero de capas variacionales (default: 1)
        """
        self.n_qubits = n_qubits
        self.n_params = n_params
        self.shots = shots
        # Soporte para m√∫ltiples capas variacionales
        self.n_layers = n_layers

        # Inicializar par√°metros aleatoriamente en [0, 2œÄ]
        self.params = np.random.rand(n_params) * 2 * np.pi

        # Historial de entrenamiento
        self.training_history = {
            'cost': [],
            'iteration': [],
            'time': []
        }

    def _cost_function(self, params: np.ndarray, X: np.ndarray, y: np.ndarray) -> float:
        """
        Calcula la funci√≥n de costo (error de clasificaci√≥n).

        La funci√≥n de costo es el porcentaje de predicciones incorrectas:
            Cost = (1/N) * Œ£ |y_pred - y_true|

        Usa batch predictions para mayor eficiencia.

        Args:
            params: Par√°metros actuales del circuito
            X: Features de forma (n_samples, 2)
            y: Labels de forma (n_samples,)

        Returns:
            float: Costo en rango [0, 1] donde 0 = clasificaci√≥n perfecta
        """
        # Usar batch prediction para mayor eficiencia
        predictions = predict_batch(X, params, self.shots, self.n_layers)

        # Calcular porcentaje de error
        errors = np.sum(predictions != y)
        cost = errors / len(y)

        return cost

    def train(self,
              X: np.ndarray,
              y: np.ndarray,
              max_iter: int = 200,
              method: str = 'COBYLA',
              verbose: bool = True,
              patience: int = 20,
              min_delta: float = 1e-4) -> Dict:
        """
        Entrena el clasificador optimizando los par√°metros.

        Utiliza scipy.optimize.minimize para encontrar par√°metros que
        minimizan la funci√≥n de costo con early stopping.

        Args:
            X: Features de entrenamiento (n_samples, 2)
            y: Labels de entrenamiento (n_samples,)
            max_iter: M√°ximo de iteraciones (default: 200)
            method: Algoritmo de optimizaci√≥n (default: 'COBYLA')
                   Opciones: 'COBYLA', 'Nelder-Mead', 'Powell'
            verbose: Si mostrar progreso (default: True)
            patience: Iteraciones sin mejora antes de parar (default: 20)
            min_delta: Mejora m√≠nima considerada significativa (default: 1e-4)

        Returns:
            dict: Informaci√≥n del entrenamiento
                - 'success': Si convergi√≥
                - 'final_cost': Costo final
                - 'iterations': Iteraciones realizadas
                - 'time': Tiempo total
                - 'stopped_early': Si se activ√≥ early stopping
        """
        if verbose:
            print(f"=== Entrenamiento del Clasificador Cu√°ntico ===")
            print(f"Dataset: {X.shape[0]} puntos")
            print(f"M√©todo: {method}")
            print(
                f"Capas variacionales: {self.n_layers} (Par√°metros: {self.n_params})")
            print(f"M√°x iteraciones: {max_iter}")
            print(
                f"Early stopping: patience={patience}, min_delta={min_delta}\n")

        start_time = time.time()

        # Variables para early stopping
        best_cost = float('inf')
        no_improvement_count = 0
        early_stopped = False

        # Callback para mostrar progreso y manejar early stopping
        def callback(params):
            nonlocal best_cost, no_improvement_count, early_stopped

            cost = self._cost_function(params, X, y)
            self.training_history['cost'].append(cost)
            current_iter = len(self.training_history['cost'])
            self.training_history['iteration'].append(current_iter)
            elapsed_time = time.time() - start_time
            self.training_history['time'].append(elapsed_time)

            # Early stopping logic
            if cost < best_cost - min_delta:
                best_cost = cost
                no_improvement_count = 0
            else:
                no_improvement_count += 1

            # Si no hay mejora durante 'patience' iteraciones, detener
            if no_improvement_count >= patience:
                early_stopped = True
                if verbose:
                    print(
                        f"\n\n‚ö†Ô∏è  Early stopping activado en iteraci√≥n {current_iter}")
                    print(
                        f"No hubo mejora en {patience} iteraciones consecutivas")
                # Forzar que scipy pare
                raise StopIteration

            if verbose:
                # Calcular barra de progreso
                progress = current_iter / max_iter
                bar_length = 20
                filled_length = int(bar_length * progress)
                bar = '‚ñà' * filled_length + '‚ñë' * (bar_length - filled_length)

                # Calcular tiempo estimado
                avg_time_per_iter = elapsed_time / current_iter if current_iter > 0 else 0
                eta = avg_time_per_iter * (max_iter - current_iter)

                # Mostrar barra (sobreescribir misma l√≠nea con \r)
                print(f"\r√âpoca {current_iter}/{max_iter} [{bar}] "
                      f"loss: {cost:.4f} (best: {best_cost:.4f}) - "
                      f"ETA: {eta:.1f}s - sin mejora: {no_improvement_count}/{patience}", end='', flush=True)

        # Optimizaci√≥n con manejo de early stopping
        try:
            result = minimize(
                fun=self._cost_function,
                x0=self.params,
                args=(X, y),
                method=method,
                options={'maxiter': max_iter},
                callback=callback
            )
        except StopIteration:
            # Early stopping activado - usar √∫ltimos par√°metros
            result = type('Result', (), {
                'x': self.params,  # Mantener par√°metros actuales
                'fun': best_cost,
                'success': True,
                'nit': len(self.training_history['cost']),
                'message': 'Early stopping'
            })()

        # Actualizar par√°metros √≥ptimos
        self.params = result.x

        training_time = time.time() - start_time

        # Obtener n√∫mero de iteraciones (no todos los optimizadores devuelven nit)
        iterations = getattr(result, 'nit', len(self.training_history['cost']))

        if verbose:
            # Salto de l√≠nea despu√©s de la barra de progreso
            print("\n")
            print(f"=== Entrenamiento Completado ===")
            if early_stopped:
                print(f"üõë Detenido por early stopping")
            print(f"Convergi√≥: {result.success}")
            print(f"Costo final: {result.fun:.4f}")
            print(f"Iteraciones: {iterations}")
            print(f"Tiempo: {training_time:.2f}s")

        return {
            'success': result.success,
            'final_cost': result.fun,
            'iterations': iterations,
            'time': training_time,
            'message': result.message,
            'stopped_early': early_stopped
        }

    def predict(self, X: np.ndarray) -> np.ndarray:
        """
        Predice clases para uno o m√∫ltiples puntos.

        Args:
            X: Features (n_samples, 2) o (2,) para un punto

        Returns:
            np.ndarray: Predicciones (n_samples,) o int para un punto
        """
        # Manejar single point (ahora con n_layers)
        if X.ndim == 1:
            return predict_single_point(X[0], X[1], self.params, self.shots, self.n_layers)

        # Manejar batch (ahora con n_layers)
        return predict_batch(X, self.params, self.shots, self.n_layers)

    def evaluate(self, X: np.ndarray, y: np.ndarray) -> float:
        """
        Calcula accuracy en un conjunto de datos.

        Args:
            X: Features (n_samples, 2)
            y: Labels verdaderos (n_samples,)

        Returns:
            float: Accuracy en rango [0, 1]
        """
        predictions = self.predict(X)
        accuracy = np.mean(predictions == y)
        return accuracy

    def save_params(self, filepath: str) -> None:
        """
        Guarda par√°metros entrenados a disco.

        Args:
            filepath: Ruta del archivo (ej: 'models/vqc_params.pkl')
        """
        data = {
            'params': self.params,
            'n_qubits': self.n_qubits,
            'n_params': self.n_params,
            'shots': self.shots,
            'n_layers': self.n_layers,  # Guardar n_layers para compatibilidad
            'training_history': self.training_history
        }

        with open(filepath, 'wb') as f:
            pickle.dump(data, f)

        print(f"Par√°metros guardados en: {filepath}")

    def load_params(self, filepath: str) -> None:
        """
        Carga par√°metros desde disco.

        Args:
            filepath: Ruta del archivo
        """
        with open(filepath, 'rb') as f:
            data = pickle.load(f)

        self.params = data['params']
        self.n_qubits = data['n_qubits']
        self.n_params = data['n_params']
        self.shots = data['shots']
        # Por compatibilidad con modelos antiguos
        self.n_layers = data.get('n_layers', 1)
        self.training_history = data['training_history']

        print(f"Par√°metros cargados desde: {filepath}")


# =============================================================================
# TESTING
# =============================================================================

if __name__ == "__main__":
    """
    Script de prueba del clasificador.
    Ejecutar: python src/classifier.py
    """
    print("=== Prueba del Clasificador Cu√°ntico ===\n")

    # Generar datos de prueba simple
    np.random.seed(42)
    X_train = np.random.rand(20, 2)
    y_train = (X_train[:, 0] + X_train[:, 1] > 1).astype(int)

    print(f"Dataset de prueba: {X_train.shape}")
    print(f"Distribuci√≥n clases: {np.bincount(y_train)}\n")

    # Crear y entrenar clasificador
    classifier = QuantumClassifier(n_qubits=2, n_params=4, shots=50)

    print("Accuracy inicial:", classifier.evaluate(X_train, y_train))

    # Entrenar
    result = classifier.train(X_train, y_train, max_iter=30, verbose=True)

    # Evaluar
    accuracy = classifier.evaluate(X_train, y_train)
    print(f"\nAccuracy final: {accuracy:.2%}")

    # Probar predicci√≥n individual
    test_point = np.array([0.3, 0.8])
    prediction = classifier.predict(test_point)
    print(f"\nPredicci√≥n para {test_point}: Clase {prediction}")

    print("\n‚úÖ Prueba completada!")
